---
title: "A Comparison of Statistical Learning Methods for Regression"
subtitle: "OLS, LASSO, bagging: A Comparison"
author: "Andrew Bates"
date: "December 20, 2018"
header-includes:
  - \renewcommand{\abstractname}{Executive Summary}
output: 
  bookdown::pdf_document2:
    toc: false
geometry: margin=1in
fontsize: 11pt
bibliography: ["references.bib"]
nocite: | 
 @broom, @R-car, @R-caret, @R-corrplot, @R-dplyr, @R-ggplot2, @Rglmnet, @R-MASS, @R-purrr, @R-randomForest, @R-recipes, @R-kableExtra, @R-here
abstract: "This is the executive summary."
---


# Introduction

In 2001 Leo Breiman described two approaches to analyzing data with statistical models [@breiman2001]. In *data modeling* we specify a stochastic model for the data, one that has known theoretical properties, and the main purpose is usually to make inferences on the population of interest. In the other approach, what Breiman calls *algorithmic modeling*, the focus is less on the the structure of the data itself and more about the output of the model. We are not concerned about finding a model that satisfies the theoretical assumptions needed to make inferences. We are interested in whether the model can make accurate predictions on newly collected data. Data modeling is the method typically taught in statistics and is probably what most who have studied statistics think of when they think about modeling. However, there has been increased interest in algorithmic modeling recently[^1] with some, including Breiman, diminishing traditional statistical modeling. 


In this paper we compare Breiman's two modeling paradigms by analyzing Major League Baseball data with the goal of developing a model to predict a players salary. We examine one data model (linear regression), one algorithmic model (random forest), and one model at the intersection of the two approaches (LASSO). For each model, we discuss some advantages and disadvantages in terms of both predictive capability and interpretability. The primary aim is to construct a predictive model but, although prediction and interpretability are often seen at odds with one another [@breiman2001, p. 206], in some situations one may be interested in finding a balance between the two.



[^1]: See https://trends.google.com/trends/explore?date=all&geo=US&q=machine%20learning for example which shows web interest in machine learning since 2004 (accessed 12/9/2018).

# Methods

In this analysis we use the `Hitters` data from the R package `ISLR` [@R-ISLR], a companion package to *An Introduction to Statistical Learning with Applications in R* [@islrbook] containing the data sets used in the book. The Hitters data contains information on  322 players from the 1986 and 1987 Major League Baseball (MLB) seasons. There are 19 covariates included in this data set that can mostly be broken down into two categories: performance metrics for the 1986 season (number of at bats, number of home runs, etc.), and performance metrics based on a given players career (career runs, career hits, etc.). There are 16 continuous variables and three categorical variables. For the 1987 season we have the player's salary on opening day along with their league (American or National) at the beginning of the season. 

The salary variable has 59 missing observations, 18% of the data. This was too many observations to ignore so we imputed the values using k-nearest neighboors before proceeding with the analysis. After examining histograms of the continuous variables, it was evident that transformations were in order. Salary, along with several covariates, were heavily right-skewed. We chose log transformations for these variables because it is a common technique and allows us to readily interpret linear regression coefficients. In all, 11 of the 20 variables were log transformed. All numeric variables were then subsequently centered about the mean and scaled by the standard deviation.

Prior to model fitting the data was split into a training and testing set with 20% reserved for testing. All three models were trained using 5-fold cross-validation with the final model chosen to be the one with the lowest root mean squared error (RMSE). In each cross-validation run for linear regression a stepwise procedure was used with Akaike Information Criteria (AIC) as the model selection criterion. Diagnostics were run on the model chosen via cross-validation and some covariates were subsequently ommited based on variance inflation factors and correlations between the covariates. Grid search was used for hyperparameter tuning of the lasso and random forest with 10 values in each grid. For the lasso the hyperparameter is the lasso penalty and for random forest the hyperparameter is the number of randomly selected covariates considered at each split. A comparison of predictive ability for the three models was made through RMSE on the testing set. We investigate interpretability via coefficient interpretation for linear regression and lasso and variable importance for lasso and random forest.

The analysis was conducted using the statistical software R [@R-base]. This document was written using the R packages `R Markdown` [@R-rmarkdown], `knitr` [@R-knitr], and `bookdown` [@R-bookdown]. All materials used to conduct the analysis and compose the report can be found at `https://github.com/asbates/stat696/tree/master/reports/baseball`.



# Analysis

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
library(here)
library(ISLR)
library(MASS) # load MASS first to prevent from masking dplyr::select
library(dplyr)
library(purrr)
library(recipes)
library(corrplot)
library(ggplot2)
library(caret)
library(broom)
library(car)
library(glmnet)
library(randomForest)
library(knitr)
library(kableExtra)
library(gridExtra)

theme_set(theme_bw())

data("Hitters")

bball_raw <- Hitters %>% 
  rename(
    at_bats = AtBat,
    hits = Hits,
    home_runs = HmRun,
    runs = Runs,
    rbis = RBI,
    walks = Walks,
    years = Years,
    career_at_bats = CAtBat,
    career_hits = CHits,
    career_home_runs = CHmRun,
    career_runs = CRuns,
    career_rbis = CRBI,
    career_walks = CWalks,
    league = League,
    division = Division,
    put_outs = PutOuts,
    assists = Assists,
    errors = Errors,
    salary = Salary,
    new_league = NewLeague
  ) %>% 
  as_tibble()

bball <- recipe(salary ~., data = bball_raw) %>% 
  step_knnimpute(salary) %>% 
  prep() %>% 
  bake(new_data = bball_raw)

mod_log <- function(x){
  ifelse(x > 0, log(x + 0.15), -log(-x + 0.15))
}

bball_logged <- bball %>% 
  mutate(
    log_salary = log(salary), 
    log_career_abs = log(career_at_bats), 
    log_career_hits = log(career_hits), 
    log_career_runs = log(career_runs) 
  ) %>% 
  mutate(
    log_home_runs = mod_log(home_runs), 
    log_career_hrs = mod_log(career_home_runs),
    log_career_rbis = mod_log(career_rbis), 
    log_career_walks = mod_log(career_walks), 
    log_put_outs = mod_log(put_outs), 
    log_assists = mod_log(assists), 
    log_errors = mod_log(errors) 
  )

bball_log_only <- bball_logged %>% 
  select(log_salary,
         at_bats,
         hits,
         log_home_runs,
         runs,
         rbis,
         walks,
         years,
         league,
         division,
         new_league,
         log_put_outs,
         log_assists,
         log_errors,
         log_career_abs,
         log_career_hits,
         log_career_hrs,
         log_career_runs,
         log_career_rbis,
         log_career_walks
         )


```



## Exploratory Analysis

There are a few areas of concern with the data use in this analysis. The first being a number of missing values for player salary[^2]. Almost 20% of the data has missing salary values. Most of the covariates were collected for the 1986 MLB season but salary was gathered at the beginning of the following season. Most of the missing salaries are likely due to retirement as 57 players retired in 1986[^3]. The others might be missing a salary because the players returned to the minor leagues which is not uncommon in baseball. Regardless of the reason, with so many missing values we decided to impute them using k-nearest neighboors. The data set is not particulary large at 322 observations so omitting missing values would be leaving out a large chunk of the data. 

Another potential issue with this data set is the correlations between the covariates. A plot of the correlation matrix for the continuous variables is given in the appendix (Figure \@ref(fig:corrplot-initial)). Several covariates have extremely high correlations, up to 98%. We also see groupings of several covariates that have large correlations with each other. For example, the number of hits and at bats have a correlation of 97%. This should not be surprising as players can only get a hit if they are at bat. But the more troubling issue is that both have high correlations with number of runs (92% for hits and 91% for at bats) and the number of runs batted in (81% for hits and 82% for at bats). Additionally, they both have moderate correlations with number of home runs and number of walks. These are likely to present problems, especially in the linear regression model. However, the model selection procedure is based on prediction error and fits subsets of the covariates so it may not include this group of variables. For now we refrain from removing any variables and reassess the issue after model selection.

Over half of the continuous variables exhibit skewness to some degree. This is of highest concern for the linear regression model but it may also affect the fit for lasso and random forest if most of the values are clumped together. Log transformations were used to account for skewness, favored for the interpretability of coefficients in the linear regression model. An example of this skewness is seen in Figure \@ref(fig:salary-hist) where we have a histogram of salary (left) along with a histogram of log salary (right). The log transformation clearly helps with skewness but also note that after transformation salary is approximately normally distributed. Histograms of the remaining variables as well as any log transformed variables are provided in the appendix for reference. Also included are scatter plots of each covariate (or the log transformed covariate) versus log salary to assess the plausability of the linearity assumption for the linear regression model. The plots show that each predictor variable has an approximately linear relationship with log salary.


```{r salary-hist, fig.width = 6, fig.height=3, fig.cap="Histogram of player salary. The left plot is prior to transformation and the right plot is after log transforming."}
sal_hist <- 
  ggplot(bball, aes(salary)) +
  geom_histogram(bins = 30) +
  xlab("Salary")

sal_hist_log <-
  ggplot(bball_log_only, aes(log_salary)) +
  geom_histogram(bins = 30) +
  xlab("Log salary")

grid.arrange(sal_hist, sal_hist_log, ncol = 2) 
```



[^2]: None of the covariates had massing values.
[^3]: http://www.baseball-almanac.com/yearly/final.php?l=NL&y=1986




## Modeling Fitting


After splitting the data into a testing and training set, each type of model was fit to the training data set with 5-fold cross-validation. The same cross-validation training and testing sets were used for each type of model. In each case, the final model was the one that resulted in the lowest root mean squared error (RMSE), averaged over the cross-validation runs. Prior to performing cross validation each continuous predictor was first centered by the mean and scaled by the standard deviation.

For the linear regression model a backwards stepwise procedure was used on each cross validation run. The resulting fit was the one with the lowest Akaike Information Criteria and this was then used to predict on the cross-validation hold out set. The model with the lowest mean cross-validation error was then evaluated. The coefficient for log put outs has a reasonably large p-value at 0.13 but the p-values for the remaining coefficients were satisfactory. The real concern with this model is the variance inflation factors (VIF). Number of at bats had a VIF of 19.2 and number of hits had a VIF of 16.9. These are quite large and indicate collinearity issues. This should not be surprising as we noted earlier that these variables are highly correlated (97%) and they both have moderate to high correlations with other variables. Number of at bats generally has higher correlations with other covariates than number of hits so it was decided to remove at bats and keep number of hits.

After removing number of at bats from the linear regression model the collinearity issue was mostly abated. The largest VIF for this model was moderate at 5.9 (number of runs batted in). Further diagnostics were done through plotting residuals versus fitted values and a QQ plot, both of which can be found in Figure \@ref(fig:lr-diagnostics). In the left plot we see one concerning point (top left) with a rather large residual. The plot also shows a few points with variance a bit larger than most of the others. For the quantile-quantile plot, we also see a point of concern (top right) that distances itself from the remaining points. However, recall that the primary purpose of this analysis is to compare predictive performance across each class of model and not necessarily to construct a model that perfectly satisfies its assumptions. Overall, both of the diagnostic plots in Figure \@ref(fig:lr-diagnostics) are reasonable approximations and are satisfactory for our purposes. Proceding with this model, cross-validation was then performed using the same fit on each run in order to get an estimate of out-of-sample RMSE and allow for comparison with the other models.


```{r lr-diagnostics, fig.width = 6, fig.height = 3, fig.cap = "Diagnostic plots for the linear regression model. The left hand plot is residuals vs. fitted values. The right hand plot is a QQ plot of the residuals vs. normal quantiles. The blue lines are reference lines indicating zero (left) and the y=x line (right)."}

lr_step_small <- readRDS(here("reports",
                              "baseball",
                              "results",
                              "lr_step_small.rds"))

lr_aug <- augment(lr_step_small)

# residuals vs. fitted values
resid_fit <- ggplot(lr_aug, aes(x = .fitted, y = .resid)) +
  geom_point() + 
  geom_hline(yintercept = 0, color = "blue") +
  labs(x = "Fitted values", y = "Residuals")

# qq plot
qq <- ggplot(lr_aug, aes(sample = .resid)) +
  stat_qq(distribution = qnorm) +
  stat_qq_line(distribution = qnorm, color = "blue") +
  labs(x = "Theoretical quantiles", y = "Sample quantiles")

grid.arrange(resid_fit, qq, ncol = 2)

```


Lasso and random forest were fit with ten values of their respective hyperparameters on each cross-validation iteration. The parameter for the lasso is the penalty parameter on the L_1 norm of the coefficients. Ten equally spaced values were used ranging from 0.01 to 1. The optimal parameter was 0.01. For the random forest the hyperparameter is the number of randomly selected predictor variables considered at each split. Values ranged from 2 to 19 with the optimal parameter found to be 3.


## Prediction Results




# Conclusion


limitations: the most obvious is the timeline. the model constructed here should clearly (?) not be used to estimate player salaries for the next season (2019). besides the obvious issue of inflation, player salaries have experienced an inflation rate beyond that of the overall inflation rate (reference). Additionaly, elite level athletes have generally seen a tremendous growth in performance (skills, ability) over the last 32 years (reference). The game itself has also experienced an evolution (changes) that may have an impact on model performance. From rule changes, increases in overall althletic performance, and changes in player population, among others, the game of baseball has surely changed since 1986. That is not to say that the model developed here is useless however. We just want to caution the reader that one should not expect exceptional performance if this model is applied to a current MLB season (although that might be an interesting experiment). The usefulness in this analysis comes from the overall model construction procedure. This gives future analysts a starting point to work with. 

Another limiting factor of this analysis is in the available variables in the data set. Baseball statistics has improved vastly over the last 32 years (reference) and there are substantially more metrics available currently (reference). This will no doubt improve the likelihood of providing the model with the 'right' features; features that could have a major impact on model performance. Often times predictive modeling is more about coming up with (obtaining) appropriate features than a particular model (reference). another thing that might help is player position and stats associated with various positions (i'm thinking pitchers here)

If future analysts deisire to construct a model for estimating contemporary MLB player salaries, we recommend the following approach.


\newpage

# (APPENDIX) Appendix A  {-}

# Supplementary Figures

```{r corrplot-initial, fig.width=6, fig.height = 3.5, fig.cap="Correlation matrix plot of continuous variables prior to transformations. Correlations are displayed as a percent."}
bball %>% 
  select_if(is.numeric) %>% 
  cor() %>% 
  corrplot(type = "lower",
           addCoef.col = "black",
           addCoefasPercent = TRUE,
           number.cex = 0.7,
           tl.srt = 10)
```


```{r corrplot-logged, fig.width = 6, fig.height = 3.5, fig.cap = "Correlation matrix plot of continuous variables after log transformations. Correlations are displayed as a percent."}
bball_log_only %>% 
  select_if(is.numeric) %>% 
  cor() %>% 
  corrplot(type = "lower",
           addCoef.col = "black",
           addCoefasPercent = TRUE,
           number.cex = 0.7,
           tl.srt = 10)
```


```{r histos-no-log, fig.width = 6, fig.height = 4, fig.cap = "Histograms of covariates for which log transformations were not performed"}

gghist <- function(data, var, bins = 30){
  var <- enquo(var)
  ggplot(data, aes(!!var)) +
    geom_histogram(bins = bins)
}


at_bats_hist <- gghist(bball, at_bats) + xlab("At bats")
hits_hist <- gghist(bball, hits) + xlab("Hits")
runs_hist <- gghist(bball, runs) + xlab("Runs")
rbis_hist <- gghist(bball, rbis) + xlab("Runs batted in")
walks_hist <- gghist(bball, walks) + xlab("Walks")
years_hist <- gghist(bball, years, bins = 20) + xlab("Years in major league")

grid.arrange(at_bats_hist,
             hits_hist,
             runs_hist,
             rbis_hist,
             walks_hist,
             years_hist,
             ncol = 2) 

```


```{r histos-with-log, fig.height = 7.5, fig.cap = "Histograms of season level covariates that were log transformed. The left side is the variable on the original scale and the right side is the variable on the log scale."}

hr_hist <- gghist(bball, home_runs)  + xlab("Home runs")
hr_log_hist <- gghist(bball_logged, log_home_runs, bins = 20) + 
  xlab("Log home runs")

po_hist <- gghist(bball, put_outs) + xlab("Put outs")
po_log_hist <- gghist(bball_logged, log_put_outs) + 
  xlab("Log put outs")

assist_hist <- gghist(bball, assists) + xlab("Assists")
assist_log_hist <- gghist(bball_logged, log_assists) +
  xlab("Log assists")
 
error_hist <- gghist(bball, errors) + xlab("Errors")
error_log_hist <- gghist(bball_logged, log_errors, bins = 20) +
  xlab("Log errors")

grid.arrange(hr_hist,
             hr_log_hist,
             po_hist,
             po_log_hist,
             assist_hist,
             assist_log_hist,
             error_hist,
             error_log_hist,
             ncol = 2)

```


```{r histos-with-log-career, fig.height = 7.5, fig.cap = "Histograms of career level covariates that were log transformed. The left side is the variable on the original scale and the right side is the variable on the log scale."}

cat_bats_hist <- gghist(bball, career_at_bats) + xlab("Career at bats")
cat_bats_log_hist <- gghist(bball_logged, log_career_abs) +
  xlab("Log career at bats")

chits_hist <- gghist(bball, career_hits) + xlab("Career hits")
chits_log_hist <- gghist(bball_logged, log_career_hits) + 
  xlab("Log career hits")

chr_hist <- gghist(bball, career_home_runs) + xlab("Career home runs")
chr_log_hist <- gghist(bball_logged, log_career_hrs) + 
  xlab("Log career home runs")

cruns_hist <- gghist(bball, career_runs) + xlab("Career runs")
cruns_log_hist <- gghist(bball_logged, log_career_runs) +
  xlab("Log career runs")

crbi_hist <- gghist(bball, career_rbis) + xlab("Career runs batted in")
crbi_log_hist <- gghist(bball_logged, log_career_rbis) +
  xlab("Log career runs batted in")

cwalk_hist <- gghist(bball, career_walks) + xlab("Career walks")
cwalk_log_hist <- gghist(bball_logged, log_career_walks, bins = 20) +
  xlab("Log career walks")

grid.arrange(cat_bats_hist,
             cat_bats_log_hist,
             chits_hist,
             chits_log_hist,
             cruns_hist,
             cruns_log_hist,
             crbi_hist,
             crbi_log_hist,
             cwalk_hist,
             cwalk_log_hist,
             ncol = 2)

```


```{r scatters-season, fig.height = 7.5, fig.cap = "Scatter plots of log salary vs. season level covariates. The blue line is a smoothing line."}

# function to produce scatter plots
ggscatter <- function(data, var){
  var <- enquo(var)
  ggplot(data, aes(x = !!var, y = log_salary)) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
    ylab("Log salary")
}


at_bat_scat <- ggscatter(bball_log_only, at_bats) + xlab("At bats")
hits_scat <- ggscatter(bball_log_only, hits) + xlab("Hits")
hrs_scat <- ggscatter(bball_log_only, log_home_runs) + xlab("Log home runs")
runs_scat <- ggscatter(bball_log_only, runs) + xlab("Runs")
rbis_scat <- ggscatter(bball_log_only, rbis) + xlab("Runs batted in")
walks_scat <- ggscatter(bball_log_only, walks) + xlab("Walks")
years_scat <- ggscatter(bball_log_only, years) + xlab("Years")
po_scat <- ggscatter(bball_log_only, log_put_outs) + xlab("Log put outs")
assists_scat <- ggscatter(bball_log_only, log_assists) + xlab("Log assists")
errors_scat <- ggscatter(bball_log_only, log_errors) + xlab("Log errors")

grid.arrange(at_bat_scat,
             hits_scat,
             hrs_scat,
             runs_scat,
             rbis_scat,
             walks_scat,
             years_scat,
             po_scat,
             assists_scat,
             errors_scat,
             ncol = 2)

```


```{r scatters-career, fig.height = 7.5, fig.cap = "Scatter plots of log salary vs. career level covariates. The blue line is a smoothing line."}

cat_bat_scat <- ggscatter(bball_log_only, log_career_abs) + 
  xlab("Log career at bats")
chits_scat <- ggscatter(bball_log_only, log_career_hits) +
  xlab("Log career hits")
chrs_scat <- ggscatter(bball_log_only, log_career_hrs) +
  xlab("Log career home runs")
cruns_scat <- ggscatter(bball_log_only, log_career_runs) +
  xlab("Log career runs")
crbis_scat <- ggscatter(bball_log_only, log_career_rbis) +
  xlab("Log career runs batted in")
cwalks_scat <- ggscatter(bball_log_only, log_career_walks) +
  xlab("Log career walks")

grid.arrange(cat_bat_scat,
             chits_scat,
             chrs_scat,
             cruns_scat,
             crbis_scat,
             cwalks_scat,
             ncol = 2)

```


```{r categorical-plots, fig.height = 7.5, fig.cap = "Bar plots of categorical variables."}
league_bar <- ggplot(bball, aes(x = league)) +
  geom_bar() +
  scale_x_discrete("League at end of 1986 season",
                   labels = c("American", "National"))

division_bar <- ggplot(bball, aes(x = division)) +
  geom_bar() +
  scale_x_discrete("Division", labels = c("East", "West"))

new_league_bar <- ggplot(bball, aes(x = new_league)) +
  geom_bar() +
  scale_x_discrete("League at start of 1987 season",
                   labels = c("American", "National"))

grid.arrange(league_bar,
             division_bar,
             new_league_bar,
             ncol = 1)
```



# R Code


<!--
\begin{appendices}

\section{Supplementary Figures}

\section{Model Stuff}

\end{appendices}
-->

\newpage

# References
